C:\Users\HP\OneDrive\Learning\Pytorch\Pytorch-Deep-Learning-ZTM-Bourke

Machine learning is turning things (data)
into numbers and finding patterns in those
numbers.
The computer does this part.
How?
Code & math.
We're going to be writing the code.

Artificiall Intellligence AI
  Machine Learning ML
    Deep Learning DL

algorithm
Starts with
Machine learning

Inputs (Variables,Features) to Output (Class)

Yashaswi Kulshreshtha
I think you can use ML for literally anything as long as you can convert it into numbers
and program it to find patterns. Literally it could be anything any input or output from
the universe

(maybe not very simple ... )
"If you can build a simple rule-based system
that doesn't require machine learning, do
that."
- A wise software engineer ... (actually rule 1 of Google's Machine Learning Handbook)

What deep learning is good for
. Problems with long lists of rules-when the traditional
approach fails, machine learning/deep learning may help.
. Continually changing environments-deep learning can
adapt ('learn') to new scenarios.
. Discovering insights within large collections of data-can
you imagine trying to hand-craft rules for what 10 different
kinds of food look like?

typically
What deep learning is not good for
. When you need explainability-the patterns learned by a deep
learning model are typically uninterpretable by a human.
. When the traditional approach is a better option - if you can
accomplish what you need with a simple rule-based system.
. When errors are unacceptable - since the outputs of deep
learning model aren't always predictable.
. When you don't have much data - deep learning models
usually require a fairly large amount of data to produce great
results.

What is a Neural Network

Neural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms¹. They are inspired by the human brain, mimicking the way that biological neurons signal to one another¹.

Artificial neural networks (ANNs) are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer¹. Each node, or artificial neuron, connects to another and has an associated weight and threshold¹. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network¹. Otherwise, no data is passed along to the next layer of the network¹.

Neural networks rely on training data to learn and improve their accuracy over time¹. However, once these learning algorithms are fine-tuned for accuracy, they are powerful tools in computer science and artificial intelligence, allowing us to classify and cluster data at a high velocity¹. Tasks in speech recognition or image recognition can take minutes versus hours when compared to the manual identification by human experts¹.

One of the most well-known neural networks is Google’s search algorithm¹. These artificial networks may be used for predictive modeling, adaptive control and applications where they can be trained via a dataset². Self-learning resulting from experience can occur within networks, which can derive conclusions from a complex and seemingly unrelated set of information².

Quelle: Unterhaltung mit Bing, 5.11.2023
(1) What are Neural Networks? | IBM. https://www.ibm.com/topics/neural-networks.
(2) Neural network - Wikipedia. https://en.wikipedia.org/wiki/Neural_network.
(3) Neural Networks | A beginners guide - GeeksforGeeks. https://www.geeksforgeeks.org/neural-networks-a-beginners-guide/.

This document talks about:

- **Neural networks**: Artificial systems that learn from data without task-specific rules. They are based on computational models of biological neurons and connections.
- **Supervised vs unsupervised learning**: Two types of machine learning methods. Supervised learning involves input-output pairs and a teacher who provides feedback. Unsupervised learning involves finding patterns and structure in input data without feedback.
- **Evolution of neural networks**: The development of different neural network models and techniques over time, such as Hebbian learning, backpropagation, deep learning, convolutional networks, recurrent networks, and sequence-to-sequence networks.
- **Types of neural networks**: Seven examples of neural network architectures that are used for various tasks, such as multilayer perceptron, convolutional neural network, recursive neural network, recurrent neural network, long short-term memory, sequence-to-sequence, and shallow neural network.
- **Example of neural network**: A simple code that demonstrates how a neural network works with three vectors: attributes, classes, and weights¹[1]. It uses 100 iterations to fit the attributes to the classes and outputs the predictions²[2].
- **Limitations and next steps**: The challenges and drawbacks of the neural network example, such as being supervised, lacking accuracy, and not handling variable matrices. The possible ways to improve the neural network, such as creating an unsupervised model and increasing computational power³[3].

Quelle: Unterhaltung mit Bing, 5.11.2023
(1) For the ex.... undefined.
(2) The code w.... undefined.
(3) The next s.... undefined.

Inputs

to

Numerical
encoding

to

Learns
representation
(patterns/features/weights)

to

Representation
outputs


Note: "patterns" is an arbitrary term, you'll often hear "embedding", "weights", "feature representation",
"feature vectors" all referring to similar things.

Supervised
Learning

Unsupervised &
Self-supervised
Learning

Transfer
Learning

5 real world use cases for Neural Network

Sure, here are five real-world use cases for Neural Networks:

1. **Speech and Voice Recognition**: Neural networks are used in many applications today for speech and voice recognition³. They can convert spoken language into written text, and are used in voice-controlled assistants, transcription services, and more³.

2. **Fraud Prevention**: In finance, neural networks are used to detect fraudulent transactions³. They can identify patterns and anomalies that may indicate fraudulent activity, helping to protect businesses and individuals from financial loss³.

3. **eCommerce Personalization**: The neural network application in the eCommerce industry focuses more on personalizing the user experience of a site visitor³. They can recommend products based on a user's browsing history and preferences, improving the shopping experience and increasing sales³.

4. **Cybersecurity**: Neural networks are used to detect threats and anomalies that could indicate a cyber attack³. They can identify patterns in network traffic that may indicate a security breach, helping to protect data and systems³.

5. **Healthcare**: Neural networks are used in healthcare to examine patients and assist in diagnosing⁴. They can analyze medical images, predict disease progression, and personalize treatment plans⁴.

These are just a few examples of how neural networks are used in the real world. They are a powerful tool that can help solve complex problems and make our lives easier.

Quelle: Unterhaltung mit Bing, 5.11.2023
(1) 7 Real-Life Applications Of Neural Networks | TechPout. https://www.techpout.com/real-life-applications-of-neural-networks/.
(2) Case Study: Industry Use-cases of Neural Networks - Medium. https://techq.medium.com/case-study-industry-use-cases-of-neural-networks-9648a6b11312.
(3) Real-Life Applications of Neural Networks | Smartsheet. https://www.smartsheet.com/neural-network-applications.
(4) 8 Applications of Neural Networks | Analytics Steps. https://analyticssteps.com/blogs/8-applications-neural-networks.

pytorch.org

What is PyTorch?
. Most popular research deep learning framework*
. Write fast deep learning code in Python (able to run on a GPU/many
GPUs)
. Able to access many pre-built deep learning models (Torch Hub/
torchvision.models)
. Whole stack: preprocess data, model data, deploy model in your
application/cloud
. Originally designed and used in-house by Facebook/Meta (now open-
source and used by companies such as Tesla, Microsoft, OpenAl)
source: paperswithcode.com/trends February 2022


François Chollet
@fchollet
With tools like Colab, Keras, and TensorFlow, virtually
anyone can solve in a day, with no initial investment,
problems that would have required an engineering team
working for a quarter and $20k in hardware in 2014
7:03 AM · Nov 21, 2020 · Twitter for Android
and PyTorch

OpenAI Standardizes on PyTorch
We are standardizing OpenAl's deep learning framework on PyTorch. In the
past, we implemented projects in many frameworks depending on their
relative strengths. We've now chosen to standardize to make it easier for our
team to create and share optimized implementations of our models.
January 30, 2020
1 minute read

CUDA
Lomputer application
CUDA is a parallel computing platform and application
programming interface that allows software to use
certain types of graphics processing unit for general
purpose processing - an approach called general-
purpose computing on GPUs. Wikipedia
Developer(s): Nvidia
License: Proprietary
Platform: Supported GPUs
Initial release: June 23, 2007; 14 years ago
Stable release: 11.6 / January 12, 2022; 31 days ago
Operating system: Windows, Linux


What we're going to cover
(broadly)
. PyTorch basics & fundamentals (dealing with tensors and tensor operations)
· Later:
. Preprocessing data (getting it into tensors)
. Building and using pretrained deep learning models
. Fitting a model to the data (learning patterns)
. Making predictions with a model (using patterns)
. Evaluating model predictions
. Saving and loading models
. Using a trained model to make predictions on custom data




