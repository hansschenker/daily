Microsoft's Semantic Kernel is an open-source Software Development Kit (SDK) that allows you to easily combine AI services like OpenAI, Azure OpenAI, and Hugging Face with conventional programming languages like C# and Python¹. This enables the creation of AI applications that combine the best of both worlds¹.

Semantic Kernel is at the center of the copilot stack¹. It provides an AI orchestration layer that allows the combination of AI models and plugins to create new experiences for users¹. With Semantic Kernel, you can leverage the same AI orchestration patterns that power Microsoft 365 Copilot and Bing in your own apps¹.

Semantic Kernel has been engineered to allow developers to flexibly integrate AI services into their existing apps¹. It provides a set of connectors that make it easy to add memories and models¹. In this way, Semantic Kernel is able to add a simulated "brain" to your app¹. Additionally, Semantic Kernel makes it easy to add skills to your applications with AI plugins that allow you to interact with the real world¹.

You can use Semantic Kernel to orchestrate AI plugins from both OpenAI and Microsoft on top of nearly any model¹. For example, you can use Semantic Kernel to orchestrate plugins built for ChatGPT, Bing, and Microsoft 365 Copilot on top of models from OpenAI, Azure, or even Hugging Face¹.

Semantic Kernel is available in C#, Python, and Java². You can get started with Semantic Kernel by obtaining an API key from either OpenAI or Azure OpenAI and running one of the C#, Python, and Java console applications/scripts².

Quelle: Unterhaltung mit Bing, 9.11.2023
(1) Orchestrate your AI with Semantic Kernel | Microsoft Learn. https://learn.microsoft.com/en-us/semantic-kernel/overview/.
(2) GitHub - microsoft/semantic-kernel: Integrate cutting-edge LLM .... https://github.com/microsoft/semantic-kernel.
(3) Hello, Semantic Kernel! | Semantic Kernel - devblogs.microsoft.com. https://devblogs.microsoft.com/semantic-kernel/hello-world/.
(4) undefined. https://github.com/microsoft/semantic-kernel.git.

Semantic Kernel and Azure Cognitive Services (specifically Azure OpenAI) are both powerful tools provided by Microsoft, but they serve different purposes and are used in different scenarios¹:

**Semantic Kernel** is an open-source Software Development Kit (SDK) that simplifies the integration of AI services such as OpenAI, Azure OpenAI, and Hugging Face with traditional programming languages like C# and Python¹. It serves as the core component of the copilot stack, a collection of tools and plugins designed to assist in building AI-powered applications¹. Furthermore, Semantic Kernel facilitates the coordination of multiple AI services, enabling the utilization of various models for distinct tasks and facilitating seamless transitions between them¹.

On the other hand, **Azure OpenAI** is a cloud-based service that empowers you to deploy a wide range of OpenAI models to the cloud and integrate them into your applications¹. These models can be accessed through a straightforward API and seamlessly incorporated into other Azure services¹. Azure OpenAI also offers a user-friendly web interface for model testing and monitoring¹. It excels in scenarios where the scaling of AI operations and the harnessing of cloud computing capabilities are essential¹.

In terms of their APIs, both Semantic Kernel and Azure OpenAI offer support for OpenAI's text and chat completion models¹. However, the methods for incorporating these models into your projects differ between the two platforms¹. Semantic Kernel requires the use of specific methods, such as WithAzureTextCompletionService or WithAzureChatCompletionService, to integrate models into your kernel¹. Conversely, with Azure OpenAI, you must create a deployment for each model and utilize the deployment name, endpoint, and API key to access the model¹.

Semantic Kernel introduces a novel feature called semantic parameters, which provide a more intuitive approach to controlling model behavior¹. These higher-level parameters, including creativity, relevance, formality, tone, and more, allow you to fine-tune model output in a user-friendly manner¹. Semantic Kernel internally translates these semantic parameters into the appropriate conventional settings, sparing you the need to delve into the intricacies of how the models operate¹.

Quelle: Unterhaltung mit Bing, 9.11.2023
(1) Microsoft Semantic Kernel vs Azure OpenAI - C# Corner. https://www.c-sharpcorner.com/article/microsoft-semantic-kernel-vs-azure-openai/.
(2) Announcing Semantic Kernel integration with Azure Cognitive Search .... https://devblogs.microsoft.com/semantic-kernel/announcing-semantic-kernel-integration-with-azure-cognitive-search/.
(3) Semantic Kernel: What It Is and Why It Matters. https://techcommunity.microsoft.com/t5/azure-developer-community-blog/semantic-kernel-what-it-is-and-why-it-matters/ba-p/3877022.
(4) Orchestrate your AI with Semantic Kernel | Microsoft Learn. https://learn.microsoft.com/en-us/semantic-kernel/overview/.
(5) undefined. https://github.com/microsoft/semantic-kernel/blob/main/README.md.
(6) undefined. https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/dotnet/02-running-prompts-from-file.ipynb.
(7) undefined. https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/dotnet/00-getting-started.ipynb.
(8) undefined. https://github.com/microsoft/semantic-kernel/tree/main/samples/skills/ChatSkill/ChatGPT.
(9) undefined. https://github.com/microsoft/semantic-kernel/blob/main/dotnet/src/SemanticKernel/Memory/VolatileMemoryStore.cs.
(10) undefined. https://github.com/microsoft/semantic-kernel/blob/main/samples/dotnet/KernelHttpServer/README.md.
(11) undefined. https://github.com/microsoft/semantic-kernel/blob/main/samples/apps/chat-summary-webapp-react/README.md.

Semantic Kernel and LangChain are both powerful tools for integrating Large Language Models (LLMs) into applications, but they have some key differences²:

**LangChain** is a robust framework that simplifies the process of building advanced language model applications². It supports models from prominent AI platforms like OpenAI, making it a solid foundation for creating powerful, language-driven applications². LangChain is a modular framework that supports Python and JavaScript/TypeScript for simplifying the development process². Complex tasks run through a sequence of components to generate the final response². LangChain has many agents, tools, plugins, etc. out of the box¹. Moreover, LangChain has 10x more popularity, so it has about 10x more developer activity to improve it¹.

On the other hand, **Semantic Kernel** is a lightweight open-source SDK that allows developers to easily run LLM models from Azure OpenAI with conventional programming languages like C# and Python². Semantic Kernel provides a simple programming model allowing developers to add custom plugins that can be chained together, and it will automatically orchestrate the proper execution plan to achieve the user’s requests². Semantic Kernel architecture and quality is better, that's quite promising for Semantic Kernel¹.

In terms of language support, while both support Python, LangChain is built around Python and JavaScript, and it has more out-of-the-box tools and integrations². Semantic Kernel is more lightweight and also includes C#².

Whether you choose LangChain or Semantic Kernel will depend on the language your team supports and what features and integrations are included out of the box².

Quelle: Unterhaltung mit Bing, 9.11.2023
(1) Langchain vs. Semantic Kernel. https://www.spyglassmtg.com/blog/langchain-vs-semantic-kernel.
(2) Differences between semantic-kernel and langchain? #936 - GitHub. https://github.com/microsoft/semantic-kernel/issues/936.

Semantic Kernel is a powerful open-source Software Development Kit (SDK) that allows developers to easily integrate AI services such as OpenAI, Azure OpenAI, and Hugging Face with traditional programming languages like C# and Python¹. It provides a simple programming model that allows developers to add custom plugins that can be chained together, and it will automatically orchestrate the proper execution plan to achieve the user’s requests¹.

Here are some popular open-source Large Language Models (LLMs) of 2023¹:
1. Llama 2
2. OpenLLaMA
3. Falcon
4. Dolly 2.0
5. MPT
6. Guanaco
7. Bloom
8. Stanford Alpaca
9. OpenChatKit
10. GPT4All
11. FLAN-T5

Each of these frameworks has its own strengths and weaknesses, and the best choice depends on the specific requirements of your project¹. For example, some frameworks might be more suitable for certain types of tasks or have better support for certain programming languages¹.

Semantic Kernel stands out for its simplicity and flexibility. It's designed to be lightweight and easy to use, making it a great choice for developers who want to quickly and easily integrate AI services into their applications¹. However, other frameworks might offer more advanced features or better support for certain types of tasks¹.

In conclusion, while Semantic Kernel is a powerful tool for integrating AI services into applications, it's important to consider the specific requirements of your project and compare different frameworks to find the one that best meets your needs¹.

Quelle: Unterhaltung mit Bing, 9.11.2023
(1) The List of 11 Most Popular Open Source LLMs of 2023. https://www.lakera.ai/blog/open-source-llms.
(2) 5 Best Open Source LLMs (November 2023) - Unite.AI. https://www.unite.ai/best-open-source-llms/.
(3) The Large Language Model (LLM) Index | Sapling. https://sapling.ai/llm/index.
(4) Open source large language models: Benefits, risks and types. https://www.ibm.com/blog/open-source-large-language-models-benefits-risks-and-types/.
(5) OpenAI vs Open Source LLM Comparison for Document Q&A. https://georgesung.github.io/ai/llm-qa-eval-wikipedia/.

